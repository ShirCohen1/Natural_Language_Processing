{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_204244255_205790124.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a1d0b12be9f4c719c8137509583f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_725fb7e96ee5476da5be1add4aaf8fbe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d445ad5e99e45318379923714359efe",
              "IPY_MODEL_45f640840b554794a000cc658aff116d"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "725fb7e96ee5476da5be1add4aaf8fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3d445ad5e99e45318379923714359efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64d6a9071fa34af1835ea4817e32e5d3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6842f7e58f87402bbc5193413672db4f"
          },
          "model_module_version": "1.5.0"
        },
        "45f640840b554794a000cc658aff116d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26b7cf9fd3784f8784631b5a3e8f9af3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 107kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5395d273a827462a8b8beaf809ffd0d6"
          },
          "model_module_version": "1.5.0"
        },
        "64d6a9071fa34af1835ea4817e32e5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6842f7e58f87402bbc5193413672db4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "26b7cf9fd3784f8784631b5a3e8f9af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "5395d273a827462a8b8beaf809ffd0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "46f153c172a84beabbb55e8588f52bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5010e3947c8a46c0b5346b3a41acfc7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_160059b47d5440e48f5be084d6c0626c",
              "IPY_MODEL_05d5198eeb2a406eac0ef9ee216e3b43"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "5010e3947c8a46c0b5346b3a41acfc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "160059b47d5440e48f5be084d6c0626c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7757cf046fa140fe9b49fc9495277c11",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e202adac24aa4e6ca3d6639ddd471d3f"
          },
          "model_module_version": "1.5.0"
        },
        "05d5198eeb2a406eac0ef9ee216e3b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e12e7c29cde47f0b9f72745064f6865",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 32.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f407c24ab2049d8b699e65b695d0d41"
          },
          "model_module_version": "1.5.0"
        },
        "7757cf046fa140fe9b49fc9495277c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e202adac24aa4e6ca3d6639ddd471d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2e12e7c29cde47f0b9f72745064f6865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0f407c24ab2049d8b699e65b695d0d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "edfd4c87a4d441358454abfea9a049f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5b4267b4c8f4ca2a86dfd159187cdcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bb35e79f0d04426865a0c546b28f96a",
              "IPY_MODEL_2faa4d843f3e4abeae43cefc5d194ff1"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "e5b4267b4c8f4ca2a86dfd159187cdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5bb35e79f0d04426865a0c546b28f96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25ea015932e443f8b905e946bf46426e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7ef4611894a49e3b1fd005748f8385c"
          },
          "model_module_version": "1.5.0"
        },
        "2faa4d843f3e4abeae43cefc5d194ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff6ba79ad55f476f80ad82f01ae26c46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.22MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab373818e77d44eaa12ff3f0f1a242a6"
          },
          "model_module_version": "1.5.0"
        },
        "25ea015932e443f8b905e946bf46426e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e7ef4611894a49e3b1fd005748f8385c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ff6ba79ad55f476f80ad82f01ae26c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ab373818e77d44eaa12ff3f0f1a242a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b7c220db7fac4b8796a170f731a8e128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96a3369a70c54994babad83d3a9dd8c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f1f90eaf2984313baf48c53229a67b3",
              "IPY_MODEL_8d8f25ffbd5741f693a935e4f3f9e3e5"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "96a3369a70c54994babad83d3a9dd8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7f1f90eaf2984313baf48c53229a67b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_958455462b0b4ee48097419864e56e82",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dce957e60be4184a1998f0069df99ec"
          },
          "model_module_version": "1.5.0"
        },
        "8d8f25ffbd5741f693a935e4f3f9e3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ef087b5781f4c5f9fc1fa512ed34227",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.31kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9598afeb4374be0b04f6bf5a8d7b573"
          },
          "model_module_version": "1.5.0"
        },
        "958455462b0b4ee48097419864e56e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0dce957e60be4184a1998f0069df99ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3ef087b5781f4c5f9fc1fa512ed34227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a9598afeb4374be0b04f6bf5a8d7b573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "73c13e04003c46c481bf49093f596533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1753a46fe12b40118e8569d6f432378d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4029300cbf6b4753b92178e9ec7d3e24",
              "IPY_MODEL_f934947c16f0444e9e8dc4b5c2e2269b"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "1753a46fe12b40118e8569d6f432378d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "4029300cbf6b4753b92178e9ec7d3e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff8793c521bb4ca493870f74961398d0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d5a2990039d4e5f8984e905658572bc"
          },
          "model_module_version": "1.5.0"
        },
        "f934947c16f0444e9e8dc4b5c2e2269b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb196779ba144dbc9b2ad84c6bf1d21c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:14&lt;00:00, 30.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eb1660e32394a27af1211741f379f20"
          },
          "model_module_version": "1.5.0"
        },
        "ff8793c521bb4ca493870f74961398d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6d5a2990039d4e5f8984e905658572bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cb196779ba144dbc9b2ad84c6bf1d21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0eb1660e32394a27af1211741f379f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 4\n",
        "Training a simple neural net for relation classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs6PUkeRbCaO",
        "outputId": "9db41cbf-f91f-44e4-8130-db4eeacefdd6"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 8.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkOHG1qripJJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import AutoConfig, AutoModel, BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfff98b-ff9b-430a-b662-cb25138893f6"
      },
      "source": [
        "# Check if there's a GPU available for train loop\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural relation classification (RC), using BERT.\n",
        "\n",
        "The dataset that you will be working on is called SemEval Task 8 dataset (https://arxiv.org/pdf/1911.10422v1.pdf). The dataset contain only train and test split, but you are allowed to split the train dataset into dev if needed.\n",
        "\n",
        "\n",
        "The two files (train and test) are available from the course git repository (https://github.com/kfirbar/nlp-course)\n",
        "\n",
        "\n",
        "In this work we will use the hugingface framework for transformers training and inference. We recomand reading the documentation in https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification *before* you start coding. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** Write a funtion *read_data* for reading the data from a single file (either train or test). This function recieves a filepath and returns a list of sentence. Every sentence is encoded as a touple, where the first element is the sentence string and the second the label (also represented as a sting). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edad72c8-e03c-4f5d-dd3d-762fed68ddae"
      },
      "source": [
        "def read_data(filepath):\n",
        "    data = []\n",
        "    #TODO... write your code accordingly \n",
        "    f = open(filepath, \"r\")\n",
        "    lines = f.readlines()\n",
        "    for i in range(0, len(lines)-1,4):\n",
        "      line = lines[i].split(\" \", 1)[1].strip().strip('\"')\n",
        "      label = lines[i+1].strip().split('(')[0]\n",
        "      data.append((line,label))\n",
        "    return data\n",
        "\n",
        "!git clone https://github.com/kfirbar/nlp-course\n",
        "train = read_data('/content/nlp-course/TRAIN_FILE.TXT')\n",
        "test = read_data('/content/nlp-course/TEST_FILE_FULL.TXT')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 71 (delta 29), reused 40 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "Pytorch require the labels to be integers. Create a mapper (dictionary) from the string labels to integers (starting zero). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8"
      },
      "source": [
        "def create_label_mapper(data):\n",
        "  label2id = {}\n",
        "  counter = 0 \n",
        "  for i in range(len(data)):\n",
        "    label = data[i][1]\n",
        "    if label not in label2id:\n",
        "      label2id[label] = counter\n",
        "      counter += 1 \n",
        "  return label2id\n",
        "\n",
        "ids = create_label_mapper(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOd_2YfxBu7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea554b3-d485-4f8e-8098-552348b15284"
      },
      "source": [
        "print(f'Number of unique labels: {len(ids)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique labels: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** Write a function *prepare_data* that takes one of the [train, test] datasets and convert each pair of (words,labels) to a pair of indexes. The function also aggregate the samples into batches. BERT Uses pretrained tokanization and embedding. you can access the tokanization and indexing using the BertTokenizer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ipTgAWN2pxA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "1a1d0b12be9f4c719c8137509583f634",
            "725fb7e96ee5476da5be1add4aaf8fbe",
            "3d445ad5e99e45318379923714359efe",
            "45f640840b554794a000cc658aff116d",
            "64d6a9071fa34af1835ea4817e32e5d3",
            "6842f7e58f87402bbc5193413672db4f",
            "26b7cf9fd3784f8784631b5a3e8f9af3",
            "5395d273a827462a8b8beaf809ffd0d6",
            "46f153c172a84beabbb55e8588f52bf9",
            "5010e3947c8a46c0b5346b3a41acfc7c",
            "160059b47d5440e48f5be084d6c0626c",
            "05d5198eeb2a406eac0ef9ee216e3b43",
            "7757cf046fa140fe9b49fc9495277c11",
            "e202adac24aa4e6ca3d6639ddd471d3f",
            "2e12e7c29cde47f0b9f72745064f6865",
            "0f407c24ab2049d8b699e65b695d0d41",
            "edfd4c87a4d441358454abfea9a049f9",
            "e5b4267b4c8f4ca2a86dfd159187cdcb",
            "5bb35e79f0d04426865a0c546b28f96a",
            "2faa4d843f3e4abeae43cefc5d194ff1",
            "25ea015932e443f8b905e946bf46426e",
            "e7ef4611894a49e3b1fd005748f8385c",
            "ff6ba79ad55f476f80ad82f01ae26c46",
            "ab373818e77d44eaa12ff3f0f1a242a6"
          ]
        },
        "outputId": "b848ca94-744b-4d22-c7ac-2a6b23184577"
      },
      "source": [
        "def map_label(row):\n",
        "    return ids[row]\n",
        "\n",
        "def prepare_data(data, tokenizer, batch_size=16): \n",
        "    data_sequences = [] #list of 3 tensors, each element is of batch size\n",
        "\n",
        "    data = train\n",
        "    df = pd.DataFrame(data, columns = ['Sentence', 'Label'])\n",
        "    \n",
        "    # Sort the date according to sentence size\n",
        "    df.sort_values(by=\"Sentence\", key=lambda x: x.str.len(), inplace = True)\n",
        "    df.reset_index(inplace = True)\n",
        "    df['mapped_label'] = df['Label'].apply(map_label)\n",
        "\n",
        "    for i in range(0, len(data)-batch_size+1, batch_size):\n",
        "      labelsofbatch = list(df['mapped_label'][i:i+batch_size])\n",
        "      sentences = list(df['Sentence'][i:i+batch_size])\n",
        "        \n",
        "      encoded_dict = tokenizer(\n",
        "                        sentences,                      \n",
        "                        add_special_tokens = True, \n",
        "                        return_attention_mask = True,\n",
        "                        return_token_type_ids = False,\n",
        "                        return_tensors = 'pt',  \n",
        "                        padding = True               \n",
        "                   )\n",
        "      \n",
        "      # Sentence encoding, masks, and label of batch\n",
        "      input_per_batch = encoded_dict['input_ids']\n",
        "      mask_per_batch = encoded_dict['attention_mask']\n",
        "      labels = torch.tensor(labelsofbatch) \n",
        "      data_sequences.append((input_per_batch, mask_per_batch, labels))\n",
        "    return data_sequences\n",
        "\n",
        "num_labels = len(ids)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',num_labels=num_labels)\n",
        "train_sequences = prepare_data(train, tokenizer)\n",
        "test_sequences = prepare_data(test, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a1d0b12be9f4c719c8137509583f634",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46f153c172a84beabbb55e8588f52bf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edfd4c87a4d441358454abfea9a049f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3n4cCb8wpXE"
      },
      "source": [
        "**Task 3:** In this part we classify the sentences using the BertForSequenceClassification model. To save resources, we initialize the optimizer with the final layer of the model. You are also allowed to change the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "b7c220db7fac4b8796a170f731a8e128",
            "96a3369a70c54994babad83d3a9dd8c7",
            "7f1f90eaf2984313baf48c53229a67b3",
            "8d8f25ffbd5741f693a935e4f3f9e3e5",
            "958455462b0b4ee48097419864e56e82",
            "0dce957e60be4184a1998f0069df99ec",
            "3ef087b5781f4c5f9fc1fa512ed34227",
            "a9598afeb4374be0b04f6bf5a8d7b573",
            "73c13e04003c46c481bf49093f596533",
            "1753a46fe12b40118e8569d6f432378d",
            "4029300cbf6b4753b92178e9ec7d3e24",
            "f934947c16f0444e9e8dc4b5c2e2269b",
            "ff8793c521bb4ca493870f74961398d0",
            "6d5a2990039d4e5f8984e905658572bc",
            "cb196779ba144dbc9b2ad84c6bf1d21c",
            "0eb1660e32394a27af1211741f379f20"
          ]
        },
        "id": "16JQeHW2iBUF",
        "outputId": "cb75d644-3fae-45c6-f223-303c536856a4"
      },
      "source": [
        "# def get_parameters(params):\n",
        "#   # TODO - your code...\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels).to(device)\n",
        "\n",
        "# Optimizer (ADAM is a fancy version of SGD)\n",
        "# optimizer = torch.optim.Adam(get_parameters(model.named_parameters()), lr=0.0001)\n",
        "\n",
        "# We decided to use all layers for high performence of the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c220db7fac4b8796a170f731a8e128",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73c13e04003c46c481bf49093f596533",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** Write a training loop, which takes a BertForSequenceClassification model and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam. You are allowed to split the train to train and dev sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Yt05uTQUY-"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) #/ len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkHfjT3k0HM"
      },
      "source": [
        "model.cuda()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "def train_loop(model, n_epochs, train_data, dev_data):\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  total_steps = len(train_data) * n_epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, \n",
        "                                              num_training_steps = total_steps)\n",
        "  for e in range(0, n_epochs):\n",
        "    # TODO - your code goes here...\n",
        "    model.train()\n",
        "    training_stats = []\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in train_data: # For each batch of training data\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=input_mask\n",
        "                        )\n",
        "        \n",
        "        loss = criterion(outputs.logits, labels) \n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
        "        optimizer.step() \n",
        "        scheduler.step()         \n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_data)\n",
        "    print(f'Average training loss on epoch {e+1}: {avg_train_loss}')\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_data: # For each batch of training data\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            output = model(input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=input_mask\n",
        "                                   )\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        loss = criterion(outputs.logits, labels) \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = output.logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(train_data)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches\n",
        "    avg_val_loss = total_eval_loss / len(train_data)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILdXH_LIw3jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37703ad0-1a60-4e2d-adb1-522d6efdcb1c"
      },
      "source": [
        "n_epochs = 2\n",
        "train_size = int(0.95 * len(train_sequences))\n",
        "val_size = len(train_sequences) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples\n",
        "train_dataset, val_dataset = random_split(train_sequences, [train_size, val_size])\n",
        "\n",
        "train_loop(model, n_epochs, train_dataset, val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average training loss on epoch 1: 1.1648599873718462\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.19\n",
            "Average training loss on epoch 2: 0.43785278848911585\n",
            "  Accuracy: 0.72\n",
            "  Validation Loss: 0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (10 labels in total), and for all labels together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQAjGaqmd8U"
      },
      "source": [
        "def evaluate(model, test_data, caption):\n",
        "  # TODO - your code goes here\n",
        "  model.eval()\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "  lables_test = []\n",
        "  lables_pred = []\n",
        "\n",
        "  for batch in test_data:\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "      with torch.no_grad():        \n",
        "        outputs = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask\n",
        "                       )\n",
        "        \n",
        "      # Move logits and labels to CPU\n",
        "      logits = outputs.logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      # True labels\n",
        "      lables_test  += list(label_ids)\n",
        "\n",
        "      # Predicted label\n",
        "      pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "      lables_pred += list(pred_flat)\n",
        "\n",
        "  print(caption)\n",
        "  print(classification_report(lables_test, lables_pred, zero_division = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TQIgl_KX2MX",
        "outputId": "ecf4ddd2-4754-4ba8-d1a8-5011de66d41e"
      },
      "source": [
        "evaluate(model, test_sequences, 'BERT model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92       941\n",
            "           1       0.92      0.73      0.81      1410\n",
            "           2       0.93      0.96      0.94       504\n",
            "           3       0.94      0.97      0.95       690\n",
            "           4       0.95      0.97      0.96      1003\n",
            "           5       0.95      0.98      0.97       845\n",
            "           6       0.92      0.97      0.94       540\n",
            "           7       0.92      0.99      0.96       634\n",
            "           8       0.87      0.95      0.91       717\n",
            "           9       0.91      0.95      0.93       716\n",
            "\n",
            "    accuracy                           0.92      8000\n",
            "   macro avg       0.92      0.94      0.93      8000\n",
            "weighted avg       0.92      0.92      0.92      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkeUfncUl42"
      },
      "source": [
        "**Task 6:** In this part we'll improve the model accuracy by using a method called \"entity markers - Entity start\". The main idea of this approch is to add special markers ([e1], [\\e1], ...) before and after each of the tagged entities. instead of using the CLS toekn for clasification, we will use the concatination of the embedding of [e1] and [e2] as shown in the image below. The complete method is described in details in the following paper - https://arxiv.org/pdf/1906.03158.pdf (specifically in Section 3.2). To use this method we'll need to create a new data load and a new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKhIbJuzc_EE"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTRk1T81VoXj"
      },
      "source": [
        "The new methods require the usage of special tokens. The following code will add the required tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU8jayVXYGsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ea8002-07e7-4e1b-d4ea-9944bf0afde3"
      },
      "source": [
        "tokenizer.add_tokens(['<e1>', '</e1>', '<e2>', '</e2>'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2UMaxjFYOB7"
      },
      "source": [
        "Create a new dataloader that add entity markers to the dataset and return their indexes as part of the new sample (the expected sample should be (s, l, i) where s is the sentence embedding, l is the label, and i is a touple with the indexes of the start entities)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMMMR1kSYnc3"
      },
      "source": [
        "def entities_indices(sent):\n",
        "  len_marker = len(\"<e1>\")\n",
        "  s1 = sent.find(\"<e1>\") + len_marker\n",
        "  s2 = sent.find(\"<e2>\") + len_marker\n",
        "  return (s1, s2)\n",
        "\n",
        "def prepare_data_MTB(data, tokenizer, batch_size=8):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "    df = pd.DataFrame(data, columns = ['Sentence', 'Label'])\n",
        "    df.sort_values(by=\"Sentence\", key=lambda x: x.str.len(), inplace = True)\n",
        "    df.reset_index(inplace = True)\n",
        "    df['mapped_label'] = df['Label'].apply(map_label)\n",
        "    df['start_entities'] = df['Sentence'].apply(entities_indices)\n",
        "\n",
        "    for i in range(0, len(data)-batch_size+1, batch_size):\n",
        "          sentences = list(df['Sentence'][i:i+batch_size])\n",
        "          batch_labels = list(df['mapped_label'][i:i+batch_size])\n",
        "          start_entities = list(df['start_entities'][i:i+batch_size])\n",
        "\n",
        "          encoded_dict = tokenizer(\n",
        "                            sentences,                      \n",
        "                            add_special_tokens = True, \n",
        "                            return_attention_mask = True,\n",
        "                            return_token_type_ids = False,\n",
        "                            return_tensors = 'pt',  \n",
        "                            padding = True               \n",
        "                      )\n",
        "          \n",
        "          # Sentence encoding, label of batch and start entities\n",
        "          s = encoded_dict['input_ids']\n",
        "          l = torch.tensor(batch_labels) \n",
        "          i = torch.tensor(start_entities) \n",
        "\n",
        "          data_sequences.append((s, l, i))\n",
        "\n",
        "    return data_sequences\n",
        "\n",
        "train_sequences = prepare_data_MTB(train, tokenizer)\n",
        "test_sequences = prepare_data_MTB(test, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AztAwecuYyt3"
      },
      "source": [
        "Create a new model that uses the \"entity markers - Entity start\" method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqHQxYttkNgg"
      },
      "source": [
        "We did not have enough time to get the new model train loop to compile and return an output. The idea that we wanted to implement was have a similar model to the previous task but have this model take additional parameters, the concatination of the embedding of [e1] and [e2] and the indicies of the entity markers. These additional parameters should in theory return more accurate results as the model is receiving more exact information on the location of these entities to classify. \n",
        "\n",
        "In the previous task, the model may not know the difference between the ordering of e1 and e2. Here since we provide their indicies the model can better predict the relationship between them given their ordering and context in sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpFlxPFY5mD"
      },
      "source": [
        "class MTB(nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "      self.config = AutoConfig.from_pretrained(base_model_name)\n",
        "      super().__init__()\n",
        "      self.model = AutoModel.from_config(self.config)\n",
        "      self.position_ids = None\n",
        "      # TODO - your code...\n",
        "\n",
        "      self.num_labels = self.config.num_labels\n",
        "      self.bert = BertModel(self.config, add_pooling_layer=False)\n",
        "      self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "      self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
        "      # self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        next_sentence_label=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None):\n",
        "      # TODO - your code...\n",
        "       \n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)\n",
        "\n",
        "        total_loss = None\n",
        "        if labels is not None and next_sentence_label is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
        "            next_sentence_loss = loss_fct(seq_relationship_score.view(-1, 2), next_sentence_label.view(-1))\n",
        "            total_loss = masked_lm_loss + next_sentence_loss\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (prediction_scores, seq_relationship_score) + outputs[2:]\n",
        "            return ((total_loss,) + output) if total_loss is not None else output\n",
        "\n",
        "        return BertForPreTrainingOutput(\n",
        "            loss=total_loss,\n",
        "            prediction_logits=prediction_scores,\n",
        "            seq_relationship_logits=seq_relationship_score,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "model = MTB('bert-base-uncased').to(device)\n",
        "\n",
        "#BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYUq5HvjWhSo"
      },
      "source": [
        "def train_MTB(model, n_epochs, train_data, dev_data):\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  total_steps = len(train_data) * n_epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, \n",
        "                                              num_training_steps = total_steps)\n",
        "  for e in range(0, n_epochs):\n",
        "    # TODO - your code goes here...\n",
        "    model.train()\n",
        "    training_stats = []\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in train_data: # For each batch of training data\n",
        "        input_ids = batch[0].to(device)\n",
        "        index = batch[2].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        print(index.shape)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids,position_ids=index\n",
        "                        \n",
        "                        )\n",
        "        \n",
        "        loss = criterion(outputs.logits, labels) \n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # to help prevent the \"exploding gradients\" problem\n",
        "        optimizer.step() # update params\n",
        "        scheduler.step() # update learning rate        \n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_data)\n",
        "    print(f'Average training loss on epoch {e+1}: {avg_train_loss}')\n",
        "\n",
        "    #Evaluation on validation set\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_data: # For each batch of training data\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            output = model(input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=input_mask\n",
        "                          \n",
        "                                   )\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        loss = criterion(outputs.logits, labels) \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = output.logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(train_data)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(train_data)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwCczHeZjaw"
      },
      "source": [
        "Use the new dataloader and model to train and evaluate the new model as in task 4 and 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46XVrTHZxcu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "b121f61b-4c6e-44a1-f687-dced649684dd"
      },
      "source": [
        "train_size = int(0.95 * len(train_sequences))\n",
        "val_size = len(train_sequences) - train_size\n",
        "\n",
        "n_epochs = 1\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(train_sequences, [train_size, val_size])\n",
        "\n",
        "train_MTB(model, n_epochs, train_dataset, val_dataset)\n",
        "\n",
        "\n",
        "# train_loop(model, n_epochs, train_sequences, dev_data)\n",
        "evaluate(model, test_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a55340479064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_MTB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c3f23c23a772>\u001b[0m in \u001b[0;36mtrain_MTB\u001b[0;34m(model, n_epochs, train_data, dev_data)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         outputs = model(input_ids,position_ids=index\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-27edcd8cfb53>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, next_sentence_label, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         )\n\u001b[1;32m    991\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (26) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ]
}